# Tensor Core

<iframe src="https://vdn1.vzuu.com/SD/1fd55a3c-9362-11eb-a595-1278b449b310.mp4?disable_local_cache=1&auth_key=1629821329-0-0-55d3ee286f8910bf78eb2515aa2ff884&f=mp4&bu=pico&expiration=1629821329&v=hw" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> 
</iframe>

<iframe src="https://vdn1.vzuu.com/SD/5a1ec0e0-7e84-11eb-aca1-aa09f3df2eff.mp4?disable_local_cache=1&auth_key=1629821800-0-0-55ef3f38466d4c0e0582af3a7375b0b3&f=mp4&bu=pico&expiration=1629821800&v=hw" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> 
</iframe>



第一代是在Volta架构中提出的，专为深度学习中的矩阵计算而设计

> 通过 FP16 和 FP32 下的混合精度矩阵乘法提供了突破性的性能 – 与 NVIDIA Pascal 相比，用于训练的峰值 teraFLOPS (TFLOPS) 性能提升了高达 **12 倍**，用于推理的峰值 TFLOPS 性能提升了高达 6 倍。这项关键功能使 Volta 提供了比 Pascal 高 3 倍的训练和推理性能

主要特点：**<font color=cyan> 一个时钟周期内可以完成一个FP64 的FMA</font>**

